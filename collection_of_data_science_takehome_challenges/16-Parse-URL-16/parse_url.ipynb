{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company XYZ is an Online Travel Agent site, such as Expedia, Booking.com, etc.\n",
    "\n",
    "They haven't invested in data science yet and all the data they have about user searches are simply stored in the URLs generated when users search for a hotel. If you are not familiar with URLs, you can run a search on any OTA site and see how all search parameters are present in the URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "* [Answer question 1](#Answer-question-1)\n",
    "* [Answer question 2](#Answer-question-2)\n",
    "* [Answer question 3](#Answer-question-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 1\n",
    "<span style='color:blue'>Create a clean data set where each column is a ﬁeld in the URL, each row is a given search and the cells are the corresponding URL values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant definition\n",
    "Site = 'http://www.mysearchforhotels.com/shop/hotelsearch?'\n",
    "LenSite = len(Site)\n",
    "\n",
    "ParamPrefix = 'hotel.'\n",
    "LenParaPrefix = len(ParamPrefix)\n",
    "\n",
    "Separator = ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    \"\"\"\n",
    "    input: a url string\n",
    "    output: a dictionary which contains parameter name and its value\n",
    "    \"\"\"\n",
    "    # remove common prefix\n",
    "    assert url[LenSite-1] == '?'\n",
    "    segments = url[LenSite:].split('&')\n",
    "\n",
    "    params = {}\n",
    "    for segment in segments:\n",
    "        kvpairs = segment.split('=')\n",
    "        assert len(kvpairs) == 2\n",
    "\n",
    "        k = kvpairs[0]\n",
    "        # remove common prefix\n",
    "        assert k[LenParaPrefix-1] == '.'\n",
    "        k = k[LenParaPrefix:]\n",
    "\n",
    "        if k in params:\n",
    "            print (\"'{}' has already existed in search\".format(k))\n",
    "            params[k] = params[k] + Separator +kvpairs[1]\n",
    "        else:\n",
    "            params[k] = kvpairs[1]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parse():\n",
    "    succ_urls = []\n",
    "    fail_urls = []\n",
    "    with open(\"url_list.txt\",'rt') as inf:\n",
    "        for index,line in enumerate(inf):\n",
    "            try:\n",
    "                url = parse_url(line.strip())\n",
    "                succ_urls.append(url)\n",
    "            except:\n",
    "                fail_urls.append(line)\n",
    "                print (\"failed to parse: {}\".format(line))\n",
    "\n",
    "            # if index%1000 ==0: print '{} lines parsed'.format(index)\n",
    "\n",
    "    print( \"************ ALL DONE ************\")\n",
    "    return succ_urls,fail_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "'amenities' has already existed in search\n",
      "************ ALL DONE ************\n"
     ]
    }
   ],
   "source": [
    "succ_urls,fail_urls = load_parse()\n",
    "assert len(fail_urls) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into DataFrame\n",
    "urls = pd.DataFrame(succ_urls)\n",
    "\n",
    "# clean\n",
    "urls['checkin'] = pd.to_datetime(urls.checkin)\n",
    "urls['checkout'] = pd.to_datetime(urls.checkout)\n",
    "urls[\"children\"].fillna(0,inplace=True)\n",
    "urls['city'] = urls.city.str.replace('+',' ')\n",
    "urls['search_page'] = urls.search_page.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adults</th>\n",
       "      <th>amenities</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>children</th>\n",
       "      <th>city</th>\n",
       "      <th>couponCode</th>\n",
       "      <th>customMaximumPriceFilter</th>\n",
       "      <th>customMinimumPriceFilter</th>\n",
       "      <th>freeCancellation</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>search_page</th>\n",
       "      <th>stars_1</th>\n",
       "      <th>stars_2</th>\n",
       "      <th>stars_3</th>\n",
       "      <th>stars_4</th>\n",
       "      <th>stars_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61970</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>0</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-12</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>0</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>yes</td>\n",
       "      <td>175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>0</td>\n",
       "      <td>Hong Kong, Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>0</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13108</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-26</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>0</td>\n",
       "      <td>New York, NY, United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adults amenities    checkin   checkout children  \\\n",
       "61970      2       NaN 2015-09-13 2015-09-15        0   \n",
       "9478       2       NaN 2015-09-12 2015-09-13        0   \n",
       "12958      2       NaN 2015-09-07 2015-09-14        0   \n",
       "51269      2       NaN 2015-09-17 2015-09-19        0   \n",
       "13108      2       NaN 2015-09-26 2015-09-27        0   \n",
       "\n",
       "                              city couponCode customMaximumPriceFilter  \\\n",
       "61970  New York, NY, United States        NaN                      275   \n",
       "9478   New York, NY, United States        yes                      175   \n",
       "12958         Hong Kong, Hong Kong        NaN                      325   \n",
       "51269       London, United Kingdom        NaN                      NaN   \n",
       "13108  New York, NY, United States        NaN                      225   \n",
       "\n",
       "      customMinimumPriceFilter freeCancellation max_score min_score  \\\n",
       "61970                      NaN              NaN       NaN         4   \n",
       "9478                       NaN              NaN       NaN         4   \n",
       "12958                      NaN              yes       NaN         4   \n",
       "51269                      NaN              NaN       NaN         4   \n",
       "13108                      NaN              NaN       NaN       NaN   \n",
       "\n",
       "       search_page stars_1 stars_2 stars_3 stars_4 stars_5  \n",
       "61970            1     NaN     NaN     NaN     NaN     NaN  \n",
       "9478             1     yes     NaN     NaN     NaN     yes  \n",
       "12958            1     NaN     NaN     NaN     NaN     NaN  \n",
       "51269            1     NaN     NaN     yes     NaN     NaN  \n",
       "13108            1     NaN     NaN     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.sample(5)#glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls.to_csv(\"urls.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 2\n",
    "<span style='color:blue'>For each search query, how many amenities were selected?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    76973\n",
       "True       704\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.notnull(urls.amenities).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** most of the search doesn't specify 'amenities'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "internet                272\n",
       "yes_smoking             170\n",
       "shuttle                 111\n",
       "yes_pet                  85\n",
       "breakfast                39\n",
       "lounge                   22\n",
       "yes_smoking, yes_pet      4\n",
       "breakfast, yes_pet        1\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.amenities.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** so each search only contains one amenities, it seems the website doesn't allow include multiple amenities in the search. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_cnts = urls.amenities.map(lambda s: 0 if pd.isnull(s) else len(s.split(Separator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76973\n",
       "1      699\n",
       "2        5\n",
       "Name: amenities, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenities_cnts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer question 3\n",
    "<span style='color:blue'>Often, to measure the quality of a search algorithm, data scientists use some metric based on how often users click on the second page, third page, and so on. The idea here is that a great search algorithm should return all interesting results on the ﬁrst page and never force users to visit the other pages (how often do you click on the second page results when you search on Google? Almost never, right?).</span>\n",
    "\n",
    "<span style='color:blue'>Create a metric based on the above idea and ﬁnd the city with the worst search algorithm.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     50000\n",
       "2     11637\n",
       "3      5864\n",
       "4      3635\n",
       "5      2422\n",
       "6      1636\n",
       "7      1114\n",
       "8       740\n",
       "9       436\n",
       "10      193\n",
       "Name: search_page, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.search_page.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>London, United Kingdom</th>\n",
       "      <td>0.526588</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>0.102502</td>\n",
       "      <td>0.065329</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.030152</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York, NY, United States</th>\n",
       "      <td>0.557616</td>\n",
       "      <td>0.181357</td>\n",
       "      <td>0.094575</td>\n",
       "      <td>0.058808</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.018173</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong, Hong Kong</th>\n",
       "      <td>0.910826</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco, California, United States</th>\n",
       "      <td>0.959285</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                1         2         3   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.526588  0.187398  0.102502   \n",
       "New York, NY, United States               0.557616  0.181357  0.094575   \n",
       "Hong Kong, Hong Kong                      0.910826  0.064992  0.014254   \n",
       "San Francisco, California, United States  0.959285  0.033613  0.004853   \n",
       "\n",
       "                                                4         5         6   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.065329  0.044372  0.030152   \n",
       "New York, NY, United States               0.058808  0.038899  0.026443   \n",
       "Hong Kong, Hong Kong                      0.005260  0.002291  0.001103   \n",
       "San Francisco, California, United States  0.001420  0.000829       NaN   \n",
       "\n",
       "                                                7         8         9   \\\n",
       "city                                                                     \n",
       "London, United Kingdom                    0.020315  0.012973  0.007199   \n",
       "New York, NY, United States               0.018173  0.012660  0.007929   \n",
       "Hong Kong, Hong Kong                      0.000848  0.000339  0.000085   \n",
       "San Francisco, California, United States       NaN       NaN       NaN   \n",
       "\n",
       "                                                10  \n",
       "city                                                \n",
       "London, United Kingdom                    0.003172  \n",
       "New York, NY, United States               0.003539  \n",
       "Hong Kong, Hong Kong                           NaN  \n",
       "San Francisco, California, United States       NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.groupby('city')['search_page'].apply(lambda s: s.value_counts(normalize=True)).unstack().sort_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I will define a metric called 'first page ratio', which measures within all pages about a certain city, how many of them are on page 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstpage_ratio(s):\n",
    "    total = s.shape[0]\n",
    "    n_firstpage = (s == 1).sum()\n",
    "    return float(n_firstpage)/total\n",
    "\n",
    "city_page1_ratio = urls.groupby('city')['search_page'].agg(firstpage_ratio).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "London, United Kingdom                      0.526588\n",
       "New York, NY, United States                 0.557616\n",
       "Hong Kong, Hong Kong                        0.910826\n",
       "San Francisco, California, United States    0.959285\n",
       "Name: search_page, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_page1_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to above result, ** the city with worst search experience is London.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
